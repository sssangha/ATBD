{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8d77a2-b3ea-47a1-9f9f-f49d0ed160ab",
   "metadata": {},
   "source": [
    "# Preparing NISAR data for validation of Solid Earth requirements\n",
    "\n",
    "**Prepared by:** Emre Havazli in October 2025 replacing the initial notebook prepared by Ekaterina Tymofyeyeva, Heresh Fattahi, Sara Mirzaee, Max Zhan, and Jeff Pon March 2024<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "This notebook pre-processes data for different NISAR Solid Earth calval sites amd requirements. Subsequent validation is done via separate notebooks for the Transient, Secular, and Coseismic requirements. These are located under /ATBD_main/methods/.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397daf73-728b-4e62-a25e-2d321f41384f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<hr/>\n",
    "\n",
    "## Table of Contents: <a id='prep_TOC'></a>\n",
    "\n",
    "[**Environment Setup**](#setup)\n",
    "- [Load Python Packages](#load_packages)\n",
    "- [Define CalVal Site and Parameters](#set_calval_params)\n",
    "- [Define Directories](#set_directories)\n",
    "- [Authentication](#set_authentication)\n",
    "\n",
    "[**1. Download and Prepare Interferograms**](#prep_ifg)\n",
    "- [1.1.  Get Data List](#prep_data)\n",
    "- [1.2.  Download DEM](#prep_dem)\n",
    "- [1.3.  Create MintPy configuration file](#create_config)\n",
    "- [1.4.  Load Data into MintPy](#prep_load_data)\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b4566-7905-4d0e-8e4a-097266495e61",
   "metadata": {},
   "source": [
    "<a id='#setup'></a>\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831854a8-9258-46fd-a136-ffa7ef9f72d8",
   "metadata": {},
   "source": [
    "### Load Python Packages <a id='#load_packages'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae784898-3e41-4463-a3f9-bd701a80dd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import netrc\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.transform import from_origin\n",
    "from pyproj import Transformer\n",
    "import tile_mate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a433c2-ce25-40bc-a1db-f5c4506d3e01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Calval Site and Parameters <a id='set_calval_params'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18978e7b-b33d-4f6d-a38d-a87044275edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Basic Configuration ===\n",
    "site = \"Erta_Ale\"  # Cal/Val location ID\n",
    "requirement = \"Transient\"  # Options: 'Secular', 'Coseismic', 'Transient'\n",
    "dataset = \"NISAR_sample\"  # Dataset type: 'NISAR_sample', 'ARIA_S1', 'ARIA_S1_new'\n",
    "\n",
    "\n",
    "rundate = \"20260205\"  # Date of this Cal/Val run\n",
    "version = \"1\"         # Version of this Cal/Val run\n",
    "custom_sites = \"/home/jovyan/my_sites.txt\"  # Path to custom site metadata\n",
    "\n",
    "# === Username Detection / Creation ===\n",
    "user_file = \"/home/jovyan/me.txt\"\n",
    "if os.path.exists(user_file):\n",
    "    with open(user_file, \"r\") as f:\n",
    "        you = f.readline().strip()\n",
    "else:\n",
    "    you = input(\"Please type a username for your Cal/Val outputs: \").strip()\n",
    "    with open(user_file, \"w\") as f:\n",
    "        f.write(you)\n",
    "\n",
    "# === Load Cal/Val Site Metadata ===\n",
    "try:\n",
    "    with open(custom_sites, \"r\") as f:\n",
    "        sitedata = json.load(f)\n",
    "    site_info = sitedata[\"sites\"][site]\n",
    "except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "    raise RuntimeError(f\"Failed to load site metadata from {custom_sites}: {e}\")\n",
    "except KeyError:\n",
    "    raise ValueError(f\"Site ID '{site}' not found in {custom_sites}\")\n",
    "\n",
    "print(f\"Loaded site: {site}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00c720-2ba2-4843-a667-f2411f468204",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Directories and Files <a id='set_directories'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3be183-ef89-4ad9-b4e8-498bd85d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static base directory for Cal/Val processing\n",
    "BASE_DIR = \"/scratch/nisar-st-calval-solidearth\"\n",
    "\n",
    "# Define key path components\n",
    "site_dir = os.path.join(BASE_DIR, dataset, site)\n",
    "work_dir = os.path.join(site_dir, requirement, you, rundate, f\"v{version}\")\n",
    "gunw_dir = os.path.join(site_dir, \"products\")\n",
    "mintpy_dir = os.path.join(work_dir, \"MintPy\")\n",
    "dem_dir = os.path.join(work_dir, \"DEM\")\n",
    "\n",
    "# Create required directories\n",
    "for path in [work_dir, gunw_dir, mintpy_dir, dem_dir]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# Log directory structure\n",
    "print(f\"  Work directory: {work_dir}\")\n",
    "print(f\"  GUNW directory: {gunw_dir}\")\n",
    "print(f\"MintPy directory: {mintpy_dir}\")\n",
    "print(f\"DEM directory: {dem_dir}\")\n",
    "\n",
    "# Configuration file path\n",
    "site_code = site_info.get('calval_location')\n",
    "config_file = os.path.join(mintpy_dir, f\"{site_code}.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a50541-6604-400f-ac7e-c14361dc8dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Authentication <a id='set_authentication'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1328ea4-a4a3-452d-905e-0e4f3c5d795c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ensure_permission(path, mode=0o600):\n",
    "    if os.path.exists(path):\n",
    "        os.chmod(path, mode)\n",
    "\n",
    "# === Earthdata Login ===\n",
    "fnetrc = os.path.expanduser(\"~/.netrc\")\n",
    "earthdata_host = \"urs.earthdata.nasa.gov\"\n",
    "earthdata = False\n",
    "\n",
    "if os.path.exists(fnetrc):\n",
    "    ensure_permission(fnetrc)\n",
    "    nrc = netrc.netrc()\n",
    "    credentials = nrc.authenticators(earthdata_host)\n",
    "    if credentials:\n",
    "        earthdata_user, _, earthdata_password = credentials\n",
    "        earthdata = True\n",
    "        print(f\"Earthdata credentials found for user: {earthdata_user}\")\n",
    "\n",
    "if not earthdata:\n",
    "    print(\"\\nNEEDED to Download ARIA GUNWs\")\n",
    "    print(\"Create account at: https://urs.earthdata.nasa.gov/\")\n",
    "    earthdata_user = input(\"Earthdata username: \").strip()\n",
    "    earthdata_password = input(\"Earthdata password: \").strip()\n",
    "    with open(fnetrc, \"a\") as f:\n",
    "        f.write(f\"machine {earthdata_host}\\nlogin {earthdata_user}\\npassword {earthdata_password}\\n\")\n",
    "    ensure_permission(fnetrc)\n",
    "    print(\"Earthdata credentials saved.\")\n",
    "\n",
    "# === OpenTopography API Key ===\n",
    "fopentopo = os.path.expanduser(\"~/.topoapi\")\n",
    "if os.path.exists(fopentopo):\n",
    "    ensure_permission(fopentopo)\n",
    "    with open(fopentopo) as f:\n",
    "        opentopography_api_key = f.read().strip()\n",
    "else:\n",
    "    print(\"\\nNEEDED To Download DEMs:\")\n",
    "    print(\"Register at: https://portal.opentopography.org/login\")\n",
    "    print(\"Navigate: My Account → myOpenTopo Authorizations and API Key → Request API key\")\n",
    "    opentopography_api_key = input(\"OpenTopo API key: \").strip()\n",
    "    with open(fopentopo, \"w\") as f:\n",
    "        f.write(opentopography_api_key + \"\\n\")\n",
    "    ensure_permission(fopentopo)\n",
    "    print(\"OpenTopography API key saved.\")\n",
    "\n",
    "# === CDS (ERA5) API Key ===\n",
    "cds_config_path = os.path.expanduser(\"~/.cdsapirc\")\n",
    "if not os.path.exists(cds_config_path):\n",
    "    print(\"\\nNEEDED to use ERA5 correction:\")\n",
    "    print(\"Register and get token: https://cds.climate.copernicus.eu/how-to-api\")\n",
    "    cds_key = input(\"CDS API key (uid:api-key): \").strip()\n",
    "    with open(cds_config_path, \"w\") as f:\n",
    "        f.write(\"url: https://cds.climate.copernicus.eu/api\\n\")\n",
    "        f.write(f\"key: {cds_key}\\n\")\n",
    "    ensure_permission(cds_config_path)\n",
    "    print(\"CDS API config created.\")\n",
    "else:\n",
    "    print(\"CDS API config file detected. (Ensure it is current)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939e0c7-6b25-488a-a4b6-c5fc72b3a7de",
   "metadata": {},
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "<a id='prep_ifg'></a>\n",
    "## 1. Download and Prepare Interferograms\n",
    "\n",
    "In this initial processing step, all the necessary Level-2 unwrapped interferogram products are gathered and organized for analysis with MintPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51f44d-b58d-4862-885c-180e8e5c3df6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1. Get data list <a id='prep_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9211df-fd07-4ad2-a6c4-6890ddeaf559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date range from site metadata\n",
    "start_date = int(site_info.get('download_start_date'))\n",
    "end_date = int(site_info.get('download_end_date'))\n",
    "\n",
    "# Filter GUNW files based on date range and version\n",
    "gunw_list = []\n",
    "for filename in os.listdir(gunw_dir):\n",
    "    if filename.endswith(\".h5\"):\n",
    "        ref_date = int(filename.split('_')[12].split('T')[0])\n",
    "        sec_date = int(filename.split('_')[13].split('T')[0])\n",
    "        if start_date <= ref_date and sec_date <= end_date:\n",
    "            gunw_list.append(os.path.join(gunw_dir, filename))\n",
    "        else:\n",
    "            print(f\"Warning: Skipping malformed filename: {filename}\")         \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Sort and write list to product file for future use with ARIA-tools\n",
    "gunw_list.sort()\n",
    "product_file = os.path.join(work_dir, \"product_file.txt\")\n",
    "with open(product_file, \"w\") as f:\n",
    "    f.write(\"\\n\".join(gunw_list))\n",
    "\n",
    "print(f\"Wrote {len(gunw_list)} GUNW files to: {product_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea2d918-ccc8-4b15-b45f-a9d9e935b879",
   "metadata": {},
   "source": [
    "### 1.2. Download DEM <a id='prep_dem'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a2d9e-a276-4538-b627-e65baeeaf4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse \"lat_min lat_max lon_min lon_max\" (e.g., \"18.50 20.50 -156 -154\")\n",
    "region_str = site_info.get('analysis_region').strip(\"'\\\"\")\n",
    "lat_min, lat_max, lon_min, lon_max = map(float, region_str.split())\n",
    "\n",
    "# Reorder to left,bottom,right,top for --bbox\n",
    "bbox = [str(lon_min), str(lat_min), str(lon_max), str(lat_max)]\n",
    "\n",
    "out_dem = os.path.join(dem_dir, f\"{site}_elevation.dem\")\n",
    "\n",
    "if os.path.isfile(out_dem):\n",
    "    print(f\"{out_dem} exists, skip downloading\")\n",
    "else:\n",
    "    cmd = [\n",
    "        \"sardem\",\n",
    "        \"--bbox\", *bbox,\n",
    "        \"--output\", out_dem,\n",
    "        \"--output-format\", \"ENVI\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    try:\n",
    "        res = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "        if res.stdout:\n",
    "            print(res.stdout)\n",
    "        print(\"DEM files:\", os.listdir(dem_dir))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"sardem failed:\")\n",
    "        print(e.stdout or \"\")\n",
    "        print(e.stderr or \"\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee233f9-dd87-4d24-bf1a-252b92c41117",
   "metadata": {},
   "source": [
    "## 1.3. Download Water Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146fdb29-3a70-4c1c-8b6b-e0e794f81d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mask = f\"{work_dir}/waterMask.msk\"   # GeoTIFF file, just named .msk as requested\n",
    "res_m = 40                   # WorldCover is ~10m; NISAR is ~80m\n",
    "dst_epsg = 32611              # output CRS\n",
    "\n",
    "# -----------------------\n",
    "# 1) Download WorldCover for bounds (in lon/lat)\n",
    "# -----------------------\n",
    "bounds_ll = (lon_min, lat_min, lon_max, lat_max)\n",
    "src_arr, src_prof = tile_mate.get_raster_from_tiles(bounds_ll, tile_shortname=\"esa_world_cover_2021\")\n",
    "\n",
    "# WorldCover water class = 80 -> 0; everything else -> 1\n",
    "src_arr = np.asarray(src_arr)\n",
    "src_mask = np.where(src_arr == 80, 0, 1).astype(\"uint8\")\n",
    "\n",
    "# -----------------------\n",
    "# 2) Build destination grid in EPSG:32611 at res_m\n",
    "# -----------------------\n",
    "to_utm = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{dst_epsg}\", always_xy=True)\n",
    "\n",
    "# project the 4 corners, then take min/max\n",
    "xs, ys = [], []\n",
    "for lon, lat in [(lon_min, lat_min), (lon_min, lat_max), (lon_max, lat_min), (lon_max, lat_max)]:\n",
    "    x, y = to_utm.transform(lon, lat)\n",
    "    xs.append(x); ys.append(y)\n",
    "\n",
    "xmin, xmax = min(xs), max(xs)\n",
    "ymin, ymax = min(ys), max(ys)\n",
    "\n",
    "width  = int(np.ceil((xmax - xmin) / res_m))\n",
    "height = int(np.ceil((ymax - ymin) / res_m))\n",
    "\n",
    "dst_transform = from_origin(xmin, ymax, res_m, res_m)  # top-left = (xmin, ymax)\n",
    "dst_arr = np.zeros((height, width), dtype=\"uint8\")\n",
    "\n",
    "print(\"Projected bounds (UTM):\", xmin, ymin, xmax, ymax)\n",
    "print(\"Output shape:\", height, width)\n",
    "\n",
    "# -----------------------\n",
    "# 3) Reproject mask onto destination grid and write GeoTIFF\n",
    "# -----------------------\n",
    "reproject(\n",
    "    source=src_mask,\n",
    "    destination=dst_arr,\n",
    "    src_transform=src_prof[\"transform\"],\n",
    "    src_crs=src_prof[\"crs\"],\n",
    "    dst_transform=dst_transform,\n",
    "    dst_crs=f\"EPSG:{dst_epsg}\",\n",
    "    resampling=Resampling.nearest,\n",
    "    src_nodata=0,\n",
    "    dst_nodata=0,\n",
    ")\n",
    "\n",
    "with rasterio.open(\n",
    "    out_mask,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=height,\n",
    "    width=width,\n",
    "    count=1,\n",
    "    dtype=\"uint8\",\n",
    "    crs=f\"EPSG:{dst_epsg}\",\n",
    "    transform=dst_transform,\n",
    "    nodata=0,\n",
    "    compress=\"DEFLATE\",\n",
    ") as dst:\n",
    "    dst.write(dst_arr, 1)\n",
    "\n",
    "print(f\"Wrote {out_mask}  (shape={dst_arr.shape}, crs=EPSG:{dst_epsg}, res={res_m}m)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c045a9-65ce-47ac-9fd3-d32d560667f8",
   "metadata": {},
   "source": [
    "### 1.4. Create MintPy configuration file <a id='create_config'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3817649-4966-4ab9-a213-27c6dddbfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(mintpy_dir)\n",
    "\n",
    "# Build config as a dictionary first\n",
    "config_file_content = {\n",
    "    \"mintpy.load.processor\": \"nisar\",\n",
    "    \"mintpy.compute.cluster\": \"local\",\n",
    "    \"mintpy.compute.numWorker\": \"auto\",\n",
    "    \"mintpy.load.waterMaskFile\": out_mask,\n",
    "    \"mintpy.topographicResidual.pixelwiseGeometry\": \"no\",\n",
    "    \"mintpy.troposphericDelay.method\": \"no\",\n",
    "    \"mintpy.topographicResidual\": \"no\",\n",
    "    \"mintpy.network.tempBaseMax\": site_info.get('tempBaseMax'),\n",
    "    \"mintpy.network.startDate\": site_info.get('download_start_date'),\n",
    "    \"mintpy.network.endDate\": site_info.get('download_end_date'),\n",
    "    \"mintpy.velocity.startDate\": site_info.get('download_start_date'),\n",
    "    \"mintpy.velocity.endDate\": site_info.get('download_end_date'),\n",
    "    \"mintpy.reference.lalo\": site_info.get('reference_lalo'),\n",
    "    \"mintpy.network.excludeDate12\": site_info.get('ifgExcludePair'),\n",
    "    \"mintpy.network.excludeDate\" : site_info.get('ifgExcludeDate'),\n",
    "    \"mintpy.network.excludeIfgIndex\" : site_info.get('ifgExcludeIndex'),\n",
    "}\n",
    "\n",
    "# Write config dictionary to text file\n",
    "with open(config_file, \"w\") as f:\n",
    "    f.writelines(f\"{k} = {v}\\n\" for k, v in config_file_content.items())\n",
    "\n",
    "# Confirm output\n",
    "print(f\"MintPy config file written to:\\n    {config_file}\\n\")\n",
    "with open(config_file, \"r\") as f:\n",
    "    print(f.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4a38e-60f3-421b-949f-aff1145e5881",
   "metadata": {},
   "source": [
    "### 1.4. Load Data into MintPy Cubes <a id='prep_load_data'></a>\n",
    "\n",
    "The output of this step is an \"inputs\" directory in 'calval_directory/calval_location/MintPy/\" containing three HDF5 files:\n",
    "- ifgramStack.h5: Contains 6 dataset cubes (e.g. unwrapped phase, coherence, connected components etc.) and multiple metadata.\n",
    "- geometryGeo.h5: Contains geometrical datasets (e.g., incidence/azimuth angle, masks, etc.).\n",
    "- ionStack.h5   : Contains pairwise ionosphere data present in the NISAR L2 GUNW.\n",
    "- tropoStack.h5 : Contains 3D interpolated total tropospheric delay correction calculated from NISAR radar grid tropospheric delay layers.\n",
    "- setStack.h5   : Contains 3D interpolated solid Earth tide correction calculated from NISAR radar grid tropospheric delay layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b57cd4-a7b0-44e8-b0df-1a1a33c90a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'prep_nisar.py -i \"{gunw_dir}/*.h5\" -d {out_dem} -m {out_mask} -o {mintpy_dir}'\n",
    "process = subprocess.run(command, shell=True)\n",
    "print('Mintpy input files:')\n",
    "[x for x in os.listdir(mintpy_dir + '/inputs') if x.endswith('.h5')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (solid_earth_atbd_dev)",
   "language": "python",
   "name": "solid_earth_atbd_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
